{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets torchaudio librosa soundfile jiwer gradio torchcodec"
      ],
      "metadata": {
        "id": "NATTS29yvcHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jhnolqsWg28A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-srQ4_I2VlO"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    Wav2Vec2ForCTC,\n",
        "    Wav2Vec2Processor,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    Wav2Vec2CTCTokenizer, # Use Wav2Vec2CTCTokenizer for direct vocab_file loading\n",
        "    Wav2Vec2FeatureExtractor # Import Wav2Vec2FeatureExtractor\n",
        ")\n",
        "import torch\n",
        "\n",
        "# -------------------------------\n",
        "# PATHS ‚Äî UPDATE THESE\n",
        "# -------------------------------\n",
        "BASE_MODEL = \"/content/drive/MyDrive/Ibibio_Voice/wav2vec2/checkpoint-3960\"   # your CV-trained model\n",
        "CUSTOM_DATASET_PATH = \"/content/drive/MyDrive/Ibibio_Voice/Data/ibb/clips\"  # if saved, otherwise load your Dataset(\"...\")\n",
        "VOCAB_PATH = \"/content/drive/MyDrive/Ibibio_Voice/wav2vec2/checkpoint-3960/vocab.json\"\n",
        "\n",
        "# --------------------------------\n",
        "# LOAD MODEL + PROCESSOR\n",
        "# --------------------------------\n",
        "# Load the feature extractor from the base model path\n",
        "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(BASE_MODEL)\n",
        "\n",
        "# Load the tokenizer using the explicit vocab file via Wav2Vec2CTCTokenizer\n",
        "tokenizer = Wav2Vec2CTCTokenizer(\n",
        "    vocab_file=VOCAB_PATH, # Pass the vocab.json path directly\n",
        "    do_lower_case=True,\n",
        "    unk_token=\"[UNK]\", # Add unk_token if not specified\n",
        "    pad_token=\"[PAD]\", # Add pad_token if not specified\n",
        "    word_delimiter_token=\"|\" # Assuming common voice setup\n",
        ")\n",
        "\n",
        "# Combine them into a Wav2Vec2Processor\n",
        "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
        "\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    vocab_size=len(processor.tokenizer),\n",
        "    pad_token_id=processor.tokenizer.pad_token_id,\n",
        "    ctc_loss_reduction=\"mean\",\n",
        ")\n",
        "\n",
        "print(\"Loaded CV-trained model ‚úì\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, math, random, json, shutil, time\n",
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd\n",
        "import torch\n",
        "print('torch', torch.__version__, 'cuda available:', torch.cuda.is_available())\n",
        "DRIVE_ROOT = '/content/drive/MyDrive/ibibio_asr'\n",
        "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
        "\n",
        "LOCAL_TSV_DIR = os.path.join(DRIVE_ROOT, 'common_voice_tsvs')\n",
        "COMMON_VOICE_DIR = os.path.join(DRIVE_ROOT, 'common_voice_23_0_ibb')\n",
        "OUTPUT_DIR = os.path.join(DRIVE_ROOT, 'wav2vec2_xlsr_optionA')\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "PRETRAINED_MODEL = 'facebook/wav2vec2-large-xlsr-53'\n",
        "SAMPLE_RATE = 16000\n",
        "MIN_AUDIO = 0.5\n",
        "MAX_AUDIO = 30.0\n",
        "\n",
        "# Pretraining vs finetuning params (defaults small for Colab)\n",
        "PRETRAIN_EPOCHS = 1   # set low for Colab testing; raise for serious pretraining\n",
        "FINETUNE_EPOCHS = 3\n",
        "PRETRAIN_BATCH = 8\n",
        "FINETUNE_BATCH = 4\n",
        "\n",
        "print('Configuration set. OUTPUT_DIR=', OUTPUT_DIR)\n"
      ],
      "metadata": {
        "id": "1fHEqotm8lTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CV_PATH = \"/content/drive/MyDrive/Ibibio_Voice/Data/ibb/\"\n",
        "print(\"CSV exists:\", os.path.exists(os.path.join(CV_PATH, \"ibbsdd.csv\")))\n",
        "print(\"Path checked:\", os.path.join(CV_PATH, \"ibbsdd.csv\"))\n"
      ],
      "metadata": {
        "id": "N1ZUc4npn-CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Ibibio_Voice/Data/ibb/ibbsdd.csv\", encoding=\"utf-8-sig\")\n",
        "print(df.columns)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "3My32s63oDiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict, Dataset, Audio\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "CV_PATH = '/content/drive/MyDrive/Ibibio_Voice/Data/ibb/'\n",
        "\n",
        "def get_duration_fixed(example):\n",
        "    \"\"\"Universal duration function that works with Audio objects\"\"\"\n",
        "    try:\n",
        "        # Get the actual file path from various possible structures\n",
        "        if hasattr(example['path'], 'path'):\n",
        "            file_path = example['path'].path\n",
        "        elif isinstance(example['path'], dict) and 'path' in example['path']:\n",
        "            file_path = example['path']['path']\n",
        "        else:\n",
        "            file_path = example['path']\n",
        "\n",
        "        if file_path and os.path.exists(file_path):\n",
        "            duration = librosa.get_duration(filename=file_path)\n",
        "            return float(duration)\n",
        "        else:\n",
        "            print(f\"File not found: {file_path}\")\n",
        "            return 0.0\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting duration: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def load_all_datasets_with_duration_filtering():\n",
        "    \"\"\"Load all datasets with duration filtering applied\"\"\"\n",
        "\n",
        "    # 1. Load the main splits (dev, test, train)\n",
        "    main_splits = {}\n",
        "    for split_name in ['ibbsdd']:\n",
        "        csv_path = os.path.join(CV_PATH, f\"{split_name}.csv\")\n",
        "        if os.path.exists(csv_path):\n",
        "            df = pd.read_csv(csv_path, sep=',', encoding='latin1', on_bad_lines='skip', engine='python')\n",
        "\n",
        "            # Ensure 'path' column is string type and handle NaN values\n",
        "            df['path'] = df['path'].astype(str)\n",
        "            df = df[df['path'] != 'nan'] # Remove rows where 'path' was NaN\n",
        "\n",
        "            # Check if df is empty after cleaning\n",
        "            if df.empty:\n",
        "                print(f\"Warning: Dataset for {split_name} is empty after cleaning 'path' column.\")\n",
        "                main_splits[split_name] = Dataset.from_pandas(pd.DataFrame(columns=['path', 'sentence', 'duration']))\n",
        "                continue\n",
        "\n",
        "            # Construct full path to audio files using CUSTOM_DATASET_PATH\n",
        "            df[\"path\"] = df[\"path\"].apply(lambda p: os.path.join(CUSTOM_DATASET_PATH, p))\n",
        "\n",
        "            dataset = Dataset.from_pandas(df)\n",
        "\n",
        "            # Add duration and filter\n",
        "            dataset = dataset.map(lambda x: {'duration': get_duration_fixed(x)})\n",
        "            dataset = dataset.filter(lambda x: MIN_AUDIO <= x['duration'] <= MAX_AUDIO)\n",
        "\n",
        "            main_splits[split_name] = dataset\n",
        "            print(f\"Loaded {split_name}: {len(dataset)} samples (after duration filtering)\")\n",
        "\n",
        "    return main_splits"
      ],
      "metadata": {
        "id": "GNdYfE739Czk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all data with duration filtering\n",
        "print(\"=== Loading datasets with duration filtering ===\")\n",
        "main_splits = load_all_datasets_with_duration_filtering()\n",
        "main_splits"
      ],
      "metadata": {
        "id": "onq8Ir-M9Fe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = main_splits.get('ibbsdd')"
      ],
      "metadata": {
        "id": "9lq8OKGj9Hw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Union, Optional\n",
        "import torch\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorCTCWithPadding:\n",
        "    processor: Wav2Vec2Processor\n",
        "    padding: Union[bool, str] = \"longest\"\n",
        "\n",
        "    def __call__(self, features: List[Dict]) -> Dict[str, torch.Tensor]:\n",
        "        # Filter out any sample that somehow has bad labels or inputs\n",
        "        clean_features = []\n",
        "        for f in features:\n",
        "            if (\n",
        "                f.get(\"input_values\") is not None\n",
        "                and f.get(\"labels\") is not None\n",
        "                and isinstance(f[\"labels\"], list)\n",
        "                and len(f[\"labels\"]) > 0\n",
        "                and all(t is not None for t in f[\"labels\"])\n",
        "            ):\n",
        "                clean_features.append(f)\n",
        "\n",
        "        if len(clean_features) == 0:\n",
        "            raise ValueError(\"All features in batch had invalid labels or inputs.\")\n",
        "\n",
        "        # Split inputs and labels\n",
        "        input_features = [{\"input_values\": f[\"input_values\"]} for f in clean_features]\n",
        "        label_features = [{\"input_ids\": f[\"labels\"]} for f in clean_features]\n",
        "\n",
        "        # Pad inputs\n",
        "        batch = self.processor.pad(\n",
        "            input_features,\n",
        "            padding=self.padding,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        # Pad labels\n",
        "        with self.processor.as_target_processor():\n",
        "            labels_batch = self.processor.pad(\n",
        "                label_features,\n",
        "                padding=self.padding,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        # Replace padding with -100 to ignore in loss\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
        "            labels_batch.attention_mask.ne(1), -100\n",
        "        )\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "        return batch\n",
        "\n",
        "data_collator = DataCollatorCTCWithPadding(processor=processor)\n"
      ],
      "metadata": {
        "id": "J7_6qt3s8pqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Ibibio_Voice/ibb_stage2_custom\",\n",
        "    group_by_length=True,\n",
        "    per_device_train_batch_size=2,  # Reduced batch size\n",
        "    per_device_eval_batch_size=2,   # Reduced batch size\n",
        "    gradient_accumulation_steps=8,\n",
        "    remove_unused_columns=False,\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    num_train_epochs=30,           # start small; you can increase later\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    save_steps=500,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,               # VERY IMPORTANT for TensorBoard\n",
        "    eval_steps=200,\n",
        "\n",
        "    learning_rate=1e-4,\n",
        "    save_total_limit=2,\n",
        "\n",
        "    report_to=[\"tensorboard\"],\n",
        "\n",
        "    # reduce GPU fragmentation\n",
        "    dataloader_num_workers=2,\n",
        ")\n",
        "model.gradient_checkpointing_enable()"
      ],
      "metadata": {
        "id": "tu3WT9Af8rHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from jiwer import wer, cer\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    pred_logits = pred.predictions\n",
        "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids)\n",
        "    # remove padding from labels\n",
        "    label_ids = pred.label_ids\n",
        "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "    label_str = processor.batch_decode(label_ids, group_tokens=False)\n",
        "\n",
        "    return {\n",
        "        \"wer\": wer(label_str, pred_str),\n",
        "        \"cer\": cer(label_str, pred_str)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "-ldozMs58xth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Audio\n",
        "\n",
        "dataset = dataset.cast_column(\"path\", Audio(sampling_rate=16000))\n"
      ],
      "metadata": {
        "id": "5SnELjnEu6v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "# Ibibio digraphs that must be treated as single symbols\n",
        "DIGRAPHS = [\"kp\", \"gb\", \"ny\", \"nw\"]\n",
        "\n",
        "# Normalize text\n",
        "def normalize_text(s):\n",
        "    s = s.lower().strip()\n",
        "    s = s.replace(\"‚Äô\", \"'\")\n",
        "\n",
        "    # keep ibibio vowels with diacritics\n",
        "    allowed = \"abcdefghijklmnopqrstuvwxyz√°√©√≠√≥√∫√†√®√¨√≤√π·ªç·ª•√± å \"\n",
        "    s = ''.join(ch for ch in s if ch in allowed)\n",
        "\n",
        "    # collapse spaces\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "# Step 1: normalize\n",
        "train_text = [normalize_text(t) for t in dataset[\"sentence\"]]\n",
        "\n",
        "# Step 2: grapheme-tokenize (detect digraphs first)\n",
        "graphemes = set()\n",
        "\n",
        "for sentence in train_text:\n",
        "    i = 0\n",
        "    while i < len(sentence):\n",
        "        # skip spaces\n",
        "        if sentence[i] == \" \":\n",
        "            graphemes.add(\" \")\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        # try matching digraph\n",
        "        matched = False\n",
        "        for dg in DIGRAPHS:\n",
        "            if sentence[i:i+len(dg)] == dg:\n",
        "                graphemes.add(dg)\n",
        "                i += len(dg)\n",
        "                matched = True\n",
        "                break\n",
        "\n",
        "        if not matched:\n",
        "            graphemes.add(sentence[i])\n",
        "            i += 1\n",
        "\n",
        "# Step 3: sort graphemes, placing space first\n",
        "graphemes = sorted(list(graphemes))\n",
        "\n",
        "# Step 4: build vocab\n",
        "vocab = {g: i for i, g in enumerate(graphemes)}\n",
        "\n",
        "# Add special CTC tokens\n",
        "vocab[\"|\"] = len(vocab)       # blank token\n",
        "vocab[\"[UNK]\"] = len(vocab)\n",
        "vocab[\"[PAD]\"] = len(vocab)\n",
        "\n",
        "# Save\n",
        "with open(\"vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(vocab, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"FINAL VOCAB:\", vocab)\n",
        "print(\"SIZE:\", len(vocab))\n"
      ],
      "metadata": {
        "id": "wZYGzeLdhP4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text_for_labels(s: str) -> str:\n",
        "    # <-- use the SAME normalize_text you used when building the vocab\n",
        "    s = s.lower()\n",
        "    s = s.replace(\"‚Äô\", \"'\")\n",
        "\n",
        "    # Ibibio digraphs that must be treated as single symbols\n",
        "    DIGRAPHS = [\"kp\", \"gb\", \"ny\", \"nw\"] # ensure this matches global DIGRAPHS\n",
        "    # Reimplement the grapheme logic used in vocab creation\n",
        "    # Here we are just normalizing, not tokenizing into graphemes\n",
        "    # The tokenizer will handle the grapheme mapping based on the vocab.json\n",
        "\n",
        "    allowed = \"abcdefghijklmnopqrstuvwxyz√°√©√≠√≥√∫√†√®√¨√≤√π·ªç·ª•√± å '\"\n",
        "    s = ''.join(ch for ch in s if ch in allowed)\n",
        "\n",
        "    # collapse spaces\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s.strip()\n",
        "\n",
        "def prepare_dataset(batch):\n",
        "    # 1) audio to input_values\n",
        "    audio = batch[\"path\"]\n",
        "    batch[\"input_values\"] = processor(\n",
        "        audio[\"array\"],\n",
        "        sampling_rate=audio[\"sampling_rate\"]\n",
        "    ).input_values[0]\n",
        "\n",
        "    # 2) normalize text & filter\n",
        "    text = normalize_text_for_labels(batch[\"sentence\"])\n",
        "    batch[\"sentence\"] = text\n",
        "\n",
        "    # if text becomes empty, mark labels None (we'll filter later)\n",
        "    if text == \"\":\n",
        "        batch[\"labels\"] = None\n",
        "        return batch\n",
        "\n",
        "    # 3) text -> label ids\n",
        "    # Use the recommended way to process labels without as_target_processor\n",
        "    batch[\"labels\"] = processor(text=text).input_ids\n",
        "\n",
        "    return batch\n"
      ],
      "metadata": {
        "id": "0RUZm-T7u8OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed = dataset.map(\n",
        "    prepare_dataset,\n",
        "    remove_columns=[c for c in dataset.column_names if c not in [\"sentence\", \"input_values\", \"labels\"]],  # remove unused cols\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "hJYH6GHZu99Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed = processed.train_test_split(test_size=0.1, seed=42)\n",
        "train_ds = processed[\"train\"]\n",
        "eval_ds = processed[\"test\"]\n"
      ],
      "metadata": {
        "id": "osB0t4YKvEPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import TrainerCallback\n",
        "\n",
        "class SavePlotsCallback(TrainerCallback):\n",
        "    \"\"\"\n",
        "    Saves training graphs (loss, WER, CER) to PNG files\n",
        "    inside the training output directory.\n",
        "    \"\"\"\n",
        "\n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        output_dir = args.output_dir\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # --------------------------\n",
        "        # Load Trainer's metrics log\n",
        "        # --------------------------\n",
        "        log_history = state.log_history\n",
        "\n",
        "        train_loss = []\n",
        "        eval_loss = []\n",
        "        wer_vals = []\n",
        "        cer_vals = []\n",
        "        steps = []\n",
        "\n",
        "        for entry in log_history:\n",
        "            if \"loss\" in entry and \"epoch\" in entry:\n",
        "                train_loss.append(entry[\"loss\"])\n",
        "                steps.append(entry[\"step\"])\n",
        "            if \"eval_loss\" in entry:\n",
        "                eval_loss.append(entry[\"eval_loss\"])\n",
        "            if \"eval_wer\" in entry:\n",
        "                wer_vals.append(entry[\"eval_wer\"])\n",
        "            if \"eval_cer\" in entry:\n",
        "                cer_vals.append(entry[\"eval_cer\"])\n",
        "\n",
        "        # --------------------------\n",
        "        # Save Training Loss Plot\n",
        "        # --------------------------\n",
        "        if train_loss:\n",
        "            plt.figure()\n",
        "            plt.plot(train_loss)\n",
        "            plt.title(\"Training Loss Curve\")\n",
        "            plt.xlabel(\"Logging Step\")\n",
        "            plt.ylabel(\"Loss\")\n",
        "            plt.grid(True)\n",
        "            plt.savefig(os.path.join(output_dir, \"training_loss.png\"))\n",
        "            plt.close()\n",
        "\n",
        "        # --------------------------\n",
        "        # Save Eval Loss Plot\n",
        "        # --------------------------\n",
        "        if eval_loss:\n",
        "            plt.figure()\n",
        "            plt.plot(eval_loss)\n",
        "            plt.title(\"Validation Loss Curve\")\n",
        "            plt.xlabel(\"Evaluation Step\")\n",
        "            plt.ylabel(\"Loss\")\n",
        "            plt.grid(True)\n",
        "            plt.savefig(os.path.join(output_dir, \"validation_loss.png\"))\n",
        "            plt.close()\n",
        "\n",
        "        # --------------------------\n",
        "        # Save WER Plot\n",
        "        # --------------------------\n",
        "        if wer_vals:\n",
        "            plt.figure()\n",
        "            plt.plot(wer_vals)\n",
        "            plt.title(\"Word Error Rate (WER)\")\n",
        "            plt.xlabel(\"Evaluation Step\")\n",
        "            plt.ylabel(\"WER\")\n",
        "            plt.grid(True)\n",
        "            plt.savefig(os.path.join(output_dir, \"wer.png\"))\n",
        "            plt.close()\n",
        "\n",
        "        # --------------------------\n",
        "        # Save CER Plot\n",
        "        # --------------------------\n",
        "        if cer_vals:\n",
        "            plt.figure()\n",
        "            plt.plot(cer_vals)\n",
        "            plt.title(\"Character Error Rate (CER)\")\n",
        "            plt.xlabel(\"Evaluation Step\")\n",
        "            plt.ylabel(\"CER\")\n",
        "            plt.grid(True)\n",
        "            plt.savefig(os.path.join(output_dir, \"cer.png\"))\n",
        "            plt.close()\n",
        "\n",
        "        print(f\"\\nüìä Saved training plots into: {output_dir}\\n\")\n"
      ],
      "metadata": {
        "id": "xjGcL46OlL9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=eval_ds,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[SavePlotsCallback()],\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(\"/content/drive/MyDrive/Ibibio_Voice/ibb_stage2_custom/\")\n",
        "\n",
        "print(\"‚úì Stage 2 training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qPkWGhtj8y9H",
        "outputId": "98aae678-f6b1-4937-9df4-700d68c21764"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1702977222.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/backends/cudnn/__init__.py:145: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  torch._C._get_cudnn_allow_tf32(),\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='625' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/720 17:13 < 02:37, 0.60 it/s, Epoch 26/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer</th>\n",
              "      <th>Cer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.662066</td>\n",
              "      <td>1.011976</td>\n",
              "      <td>0.807524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.605665</td>\n",
              "      <td>0.772455</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.559200</td>\n",
              "      <td>0.463349</td>\n",
              "      <td>0.592814</td>\n",
              "      <td>0.123824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.559200</td>\n",
              "      <td>0.438448</td>\n",
              "      <td>0.520958</td>\n",
              "      <td>0.107524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.498800</td>\n",
              "      <td>0.366206</td>\n",
              "      <td>0.455090</td>\n",
              "      <td>0.096865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.498800</td>\n",
              "      <td>0.350299</td>\n",
              "      <td>0.455090</td>\n",
              "      <td>0.092476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.363900</td>\n",
              "      <td>0.312249</td>\n",
              "      <td>0.407186</td>\n",
              "      <td>0.098119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.363900</td>\n",
              "      <td>0.289065</td>\n",
              "      <td>0.347305</td>\n",
              "      <td>0.079310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.344200</td>\n",
              "      <td>0.274879</td>\n",
              "      <td>0.323353</td>\n",
              "      <td>0.079310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.344200</td>\n",
              "      <td>0.281011</td>\n",
              "      <td>0.359281</td>\n",
              "      <td>0.078683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.305100</td>\n",
              "      <td>0.325776</td>\n",
              "      <td>0.383234</td>\n",
              "      <td>0.090596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.305100</td>\n",
              "      <td>0.218450</td>\n",
              "      <td>0.317365</td>\n",
              "      <td>0.081818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.280600</td>\n",
              "      <td>0.217007</td>\n",
              "      <td>0.299401</td>\n",
              "      <td>0.068025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.280600</td>\n",
              "      <td>0.262814</td>\n",
              "      <td>0.263473</td>\n",
              "      <td>0.072414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.261900</td>\n",
              "      <td>0.216462</td>\n",
              "      <td>0.293413</td>\n",
              "      <td>0.069279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.261900</td>\n",
              "      <td>0.230515</td>\n",
              "      <td>0.239521</td>\n",
              "      <td>0.057994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.230800</td>\n",
              "      <td>0.221054</td>\n",
              "      <td>0.251497</td>\n",
              "      <td>0.059875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.230800</td>\n",
              "      <td>0.228848</td>\n",
              "      <td>0.263473</td>\n",
              "      <td>0.061755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>0.215058</td>\n",
              "      <td>0.257485</td>\n",
              "      <td>0.069906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>0.211909</td>\n",
              "      <td>0.245509</td>\n",
              "      <td>0.063636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.191000</td>\n",
              "      <td>0.192637</td>\n",
              "      <td>0.215569</td>\n",
              "      <td>0.057994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.191000</td>\n",
              "      <td>0.192713</td>\n",
              "      <td>0.221557</td>\n",
              "      <td>0.057680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.224000</td>\n",
              "      <td>0.201099</td>\n",
              "      <td>0.233533</td>\n",
              "      <td>0.056740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.224000</td>\n",
              "      <td>0.193647</td>\n",
              "      <td>0.209581</td>\n",
              "      <td>0.049216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.225800</td>\n",
              "      <td>0.203909</td>\n",
              "      <td>0.209581</td>\n",
              "      <td>0.050470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.225800</td>\n",
              "      <td>0.212563</td>\n",
              "      <td>0.215569</td>\n",
              "      <td>0.052038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:180: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='641' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [641/720 17:49 < 02:12, 0.60 it/s, Epoch 26.69/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer</th>\n",
              "      <th>Cer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.662066</td>\n",
              "      <td>1.011976</td>\n",
              "      <td>0.807524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.605665</td>\n",
              "      <td>0.772455</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.559200</td>\n",
              "      <td>0.463349</td>\n",
              "      <td>0.592814</td>\n",
              "      <td>0.123824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.559200</td>\n",
              "      <td>0.438448</td>\n",
              "      <td>0.520958</td>\n",
              "      <td>0.107524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.498800</td>\n",
              "      <td>0.366206</td>\n",
              "      <td>0.455090</td>\n",
              "      <td>0.096865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.498800</td>\n",
              "      <td>0.350299</td>\n",
              "      <td>0.455090</td>\n",
              "      <td>0.092476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.363900</td>\n",
              "      <td>0.312249</td>\n",
              "      <td>0.407186</td>\n",
              "      <td>0.098119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.363900</td>\n",
              "      <td>0.289065</td>\n",
              "      <td>0.347305</td>\n",
              "      <td>0.079310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.344200</td>\n",
              "      <td>0.274879</td>\n",
              "      <td>0.323353</td>\n",
              "      <td>0.079310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.344200</td>\n",
              "      <td>0.281011</td>\n",
              "      <td>0.359281</td>\n",
              "      <td>0.078683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.305100</td>\n",
              "      <td>0.325776</td>\n",
              "      <td>0.383234</td>\n",
              "      <td>0.090596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.305100</td>\n",
              "      <td>0.218450</td>\n",
              "      <td>0.317365</td>\n",
              "      <td>0.081818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.280600</td>\n",
              "      <td>0.217007</td>\n",
              "      <td>0.299401</td>\n",
              "      <td>0.068025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.280600</td>\n",
              "      <td>0.262814</td>\n",
              "      <td>0.263473</td>\n",
              "      <td>0.072414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.261900</td>\n",
              "      <td>0.216462</td>\n",
              "      <td>0.293413</td>\n",
              "      <td>0.069279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.261900</td>\n",
              "      <td>0.230515</td>\n",
              "      <td>0.239521</td>\n",
              "      <td>0.057994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.230800</td>\n",
              "      <td>0.221054</td>\n",
              "      <td>0.251497</td>\n",
              "      <td>0.059875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.230800</td>\n",
              "      <td>0.228848</td>\n",
              "      <td>0.263473</td>\n",
              "      <td>0.061755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>0.215058</td>\n",
              "      <td>0.257485</td>\n",
              "      <td>0.069906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>0.211909</td>\n",
              "      <td>0.245509</td>\n",
              "      <td>0.063636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.191000</td>\n",
              "      <td>0.192637</td>\n",
              "      <td>0.215569</td>\n",
              "      <td>0.057994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.191000</td>\n",
              "      <td>0.192713</td>\n",
              "      <td>0.221557</td>\n",
              "      <td>0.057680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.224000</td>\n",
              "      <td>0.201099</td>\n",
              "      <td>0.233533</td>\n",
              "      <td>0.056740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.224000</td>\n",
              "      <td>0.193647</td>\n",
              "      <td>0.209581</td>\n",
              "      <td>0.049216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.225800</td>\n",
              "      <td>0.203909</td>\n",
              "      <td>0.209581</td>\n",
              "      <td>0.050470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.225800</td>\n",
              "      <td>0.212563</td>\n",
              "      <td>0.215569</td>\n",
              "      <td>0.052038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def transcribe(audio_dict):\n",
        "    with torch.no_grad():\n",
        "        input_values = torch.tensor(audio_dict[\"input_values\"]).unsqueeze(0)\n",
        "        logits = model(input_values).logits\n",
        "        pred_ids = torch.argmax(logits, dim=-1)\n",
        "        return processor.decode(pred_ids[0])\n"
      ],
      "metadata": {
        "id": "pZm6677680UM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}